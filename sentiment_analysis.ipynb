{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPuTJWGuv-Jm"
      },
      "source": [
        "# Flatten -> 2 D input was transformed into 1 D\n",
        "# Dense -> fully connected layers, responsible for generating weights and biases for ML \n",
        "# Embedding \n",
        "\n",
        "# converts entire string set into a VECTOR matrix! \n",
        "# averaged out to get a vector per sentence \n",
        "\n",
        "# PATTERN on the averaged vector instead!"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fotsf_gKxs9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56b41876-57af-4622-ee4a-ec471d0b565d"
      },
      "source": [
        "%%writefile train_script.py\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nr5fJTA2aP_",
        "outputId": "0ae85236-1cf4-469d-b43d-6bf4fa0b2b9a"
      },
      "source": [
        "%%writefile -a train_script.py\n",
        "\n",
        "(trainx,trainy), (testx, testy) = tf.keras.datasets.imdb.load_data(num_words=10000)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "IuajQpKB2sZa",
        "outputId": "a68f685d-e82f-41bb-d69b-85668e476c87"
      },
      "source": [
        "trainy[:5]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-74730e4f490f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trainy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0IdDtup2vbE"
      },
      "source": [
        "print(testx[9])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBIZtvvS2zIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6098b81-1e02-41eb-dd83-c68a94a87470"
      },
      "source": [
        "%%writefile -a train_script.py\n",
        "\n",
        "data = tf.keras.datasets.imdb"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcC9Up0Y299Y"
      },
      "source": [
        "dir(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5KmTyC32-02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99411ab-c327-45fd-c3bb-ce1a0549a503"
      },
      "source": [
        "%%writefile -a train_script.py\n",
        "\n",
        "reverse_dictionary = data.get_word_index()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmLteOAT3MSi"
      },
      "source": [
        "reverse_dictionary['bye']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0rq8SCf52Z1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc4b6fa-55b1-43be-c57a-3d2c0d5adbb4"
      },
      "source": [
        "%%writefile -a train_script.py\n",
        "\n",
        "word_index = {word:(encoding+3) for word,encoding in reverse_dictionary.items()}\n",
        "word_index['<PAD>'] = 0\n",
        "word_index['<START>'] = 1\n",
        "word_index['<UNK>'] = 2  # unknown words\n",
        "word_index['<UNUSED>'] = 3\n",
        "olddictionary = { encoding:word  for word,encoding in word_index.items()   }"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjoa3Vns3mZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a7532ee-8bb3-45b5-f670-18f1f1a5330f"
      },
      "source": [
        "%%writefile -a train_script.py\n",
        "\n",
        "dictionary = {}\n",
        "for i in range(10000):\n",
        "  dictionary[i] = olddictionary[i]\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVLuhkrS3oGu"
      },
      "source": [
        "len(dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFGAx-u-3zEm"
      },
      "source": [
        "# NLP keywords-> \n",
        "# 0 <PAD> \n",
        "# 1 <START>\n",
        "# 2 <UNK>\n",
        "# 3 <UNUSED>\n",
        "\n",
        "# To NORMALIZE-> we make sure all INPUTS are of SAME length\n",
        "# small sentences will be padded with 0 towards the end\n",
        "# large sentences will be CHOPPED into shorter length! "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0lLWgWW6L0R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3003452-fe3f-46de-d1f1-26d1cc6d8b52"
      },
      "source": [
        "%%writefile -a train_script.py\n",
        "\n",
        "def decoder(sampleinput):\n",
        "  return \" \".join([dictionary[word] for word in sampleinput])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "War58BVX6YEl"
      },
      "source": [
        "decoder(testx[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-6V9qvx6eQV"
      },
      "source": [
        "testy[0] # 0-> negative sentiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxsZ7eGV7RWY"
      },
      "source": [
        "testy[41] # 1-> positive sentiment!\n",
        "\n",
        "# sentiment = f(sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpRh_lwe7U_i"
      },
      "source": [
        "decoder(testx[41])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(decoder(testx[41])))\n",
        "print(len(decoder(testx[42])))\n",
        "print(len(decoder(testx[43])))\n",
        "# ALL THE SENTENCES should be made to the same length!\n",
        "# NEURAL NETWORK INPUT is of FIXED SIZE!"
      ],
      "metadata": {
        "id": "V2mXQCit5dIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg2zfEN-7bNP",
        "outputId": "b87d6d7a-5e7f-4090-c27b-f5318ffea673"
      },
      "source": [
        "%%writefile -a train_script.py\n",
        "\n",
        "xtrain_padded = keras.preprocessing.sequence.pad_sequences(trainx, value=0, padding='post',\n",
        "                                                           truncating='post', maxlen=256)\n",
        "xtest_padded = keras.preprocessing.sequence.pad_sequences(testx, value=0, padding='post', \n",
        "                                                          truncating='post', maxlen=256)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder(trainx[142]))\n",
        "print(decoder(xtrain_padded[142])) # LONG SENTENCE CHOPPED\n",
        "print(decoder(trainx[162])) # SHORT SENTENCE PADDED\n",
        "print(decoder(xtrain_padded[162]))"
      ],
      "metadata": {
        "id": "JSdSqoN6PPn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq-yRHLi8FL5"
      },
      "source": [
        "print(len(xtrain_padded[0]))\n",
        "len(xtrain_padded[42])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIMjOLV78lZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13194f3f-ff57-41e8-c5cb-cbc90b8aef9a"
      },
      "source": [
        "%%writefile -a train_script.py\n",
        "# vocab size = 10,000\n",
        "# hyperparams\n",
        "\n",
        "HP_vocab_size = 10000\n",
        "HP_input_dim = 160\n",
        "# weights generated for embedding -> 10000 X 160 => 160000 \n",
        "HP_hidden_dim = [64, 128, 256]\n",
        "HP_output_dim = 2\n",
        "HP_epochs = 50\n",
        "HP_initial_lr = 0.01\n",
        "HP_batch_size = 32\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYf1G_cSEJMh"
      },
      "source": [
        "# Assume: this was the poorer model\n",
        "\n",
        "layer1 = keras.layers.Embedding(HP_vocab_size, HP_input_dim)\n",
        "layer2 = keras.layers.GlobalAveragePooling1D()\n",
        "layer3 = keras.layers.Dense(HP_hidden_dim[0], activation = tf.nn.relu)\n",
        "layer4 = keras.layers.Dense(HP_output_dim, activation = tf.nn.softmax)\n",
        "model1 = keras.models.Sequential([layer1,layer2,layer3,layer4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUZtna9YE2FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfda0767-0316-4b92-90ac-5ea70eb6405d"
      },
      "source": [
        "%%writefile -a train_script.py\n",
        "\n",
        "# Assume: this was the better model \n",
        "\n",
        "layer1 = keras.layers.Embedding(HP_vocab_size, HP_input_dim)\n",
        "layer2 = keras.layers.GlobalAveragePooling1D()\n",
        "layer3 = keras.layers.Dense(HP_hidden_dim[1], activation = tf.nn.relu)\n",
        "layer4 = keras.layers.Dense(1, activation = tf.nn.sigmoid)\n",
        "model2 = keras.models.Sequential([layer1,layer2,layer3,layer4])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUXJNlyYFVu3"
      },
      "source": [
        "model1.compile(loss=tf.losses.sparse_categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a train_script.py\n",
        "\n",
        "model2.compile(loss=tf.losses.binary_crossentropy, optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLY9SF7wQfM4",
        "outputId": "341ebfb1-57c5-4dde-8b82-d95e43e42a44"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YW8MibvGV-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53d640f-0e37-43f5-c206-22c939dab388"
      },
      "source": [
        "%%writefile -a train_script.py\n",
        "\n",
        "xval = xtest_padded[:10000]\n",
        "xtest_new = xtest_padded[10000:]\n",
        "yval = testy[:10000]\n",
        "ytest_new = testy[10000:]\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# val dataset would otherwise make the learning slower\n",
        "# but combined with batch size, we can arrive at a middle \n",
        "# ground for speed!\n",
        "\n",
        "# val-> provides testing WHILE the training is happening!\n",
        "# scoring-> testing happens AFTER the training!\n",
        "# 3 datasets-> train_test_split(x,y)-> train, score\n",
        "#              train_test_plit(trainx,trainy)-> train, val\n",
        "# 3 datasets-> train, val, score\n",
        "# train + val- during training\n",
        "# score - for model.predict and evaluation!"
      ],
      "metadata": {
        "id": "WAUn8kF-RDbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzGhRiskJZWu"
      },
      "source": [
        "decoder(xval[29])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHH7UYWSF6QU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7c20d70-03b7-4202-ad84-44667cea557b"
      },
      "source": [
        "%%writefile -a train_script.py\n",
        "\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "history = model2.fit(xtrain_padded, trainy, epochs=5, batch_size=HP_batch_size, validation_data = (xval, yval), verbose=0) \n",
        "end_time = time.time()\n",
        "# When typically= LOG the metric-> Cloud Logging \n",
        "#print('Time Taken = ' + str(end_time-start_time))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrOgYLyt_RLU"
      },
      "source": [
        "# VECTORIZATION representing entire sentence \n",
        "# vector_math_magic() -> single vector -> fictional_boundary-> 2i-3j\n",
        "# any vector > 2i-3j should be learnt as pos, other neg!\n",
        "# AVERAGE out of it!\n",
        "# layer-> GlobalAveragePooling -> take a window of data-> calculate average-> move to next window!\n",
        "# Algorithm?\n",
        "# Calculate mega vectors -> take their average-> learn pattern on these avg via ML!\n",
        "# learn pattern on these avg via ML -> 2 dense layers so that weights and biases can be generated\n",
        "# SOFTMAX or SIGMOID-> distribution b/w pos/neg or a single probability!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL6oVDcBBfFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c95cde-c64b-4975-eedb-a41546ad3105"
      },
      "source": [
        "%%writefile -a train_script.py\n",
        "\n",
        "predictions = model2.predict(xtest_new)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sq7pjMDKk-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "055dcb13-7f24-4a00-8075-7e8005d35108"
      },
      "source": [
        "%%writefile -a train_script.py\n",
        "\n",
        "perf = model2.evaluate(xtest_new, ytest_new)\n",
        "#perf\n",
        "# instead of printing-> CLoud Logging -> log the metrics "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOyktgCDKywu"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onZYVTwTK4A3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5fa643-5ad0-4679-8519-e9a167c3bbf2"
      },
      "source": [
        "%%writefile -a train_script.py\n",
        "\n",
        "model2.save('mymodel.h5')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to train_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I5xAUZ8BSId_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}